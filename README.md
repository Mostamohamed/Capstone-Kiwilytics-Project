# ğŸš€ Total Revenue per Day ETL with Airflow

## Overview
This project demonstrates an **end-to-end automated ETL pipeline** built with **Apache Airflow**.  
It extracts sales data from a **PostgreSQL database**, transforms it using **Python (pandas)**, and calculates **total revenue per day**.  
The pipeline also generates a **time series visualization** of revenue trends, making it a strong portfolio project for **data engineering and analytics workflows**.

---

## âœ¨ Features
- **Extract**: Query order and product data from PostgreSQL  
- **Transform**: Clean, join, and aggregate revenue with pandas (`groupby` on order_date)  
- **Load**: Save results as CSV and PNG outputs for analysis  
- **Schedule**: Automated daily execution with Apache Airflow  
- **Visualize**: Generate daily revenue plots for clear trend analysis  

---

## ğŸ“‚ Project Structure
```
total_revenue_pipeline/
â”‚
â”œâ”€â”€ dags/                      
â”‚   â””â”€â”€ sales_revenue_dag.py    # Main Airflow DAG
â”œâ”€â”€ data/
â”‚   â””â”€â”€ RetailDB_postgres.sql   # Sample database schema
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ daily_sales_data.csv    # Processed sales data
â”‚   â”œâ”€â”€ daily_revenue.csv       # Aggregated daily revenue
â”‚   â””â”€â”€ daily_revenue_plot.png  # Visualization of revenue trends
â””â”€â”€ README.md                   
```

---

## âš™ï¸ Pipeline Workflow
The Airflow DAG (`sales_revenue_pipeline`) includes three main tasks:

1. **Extract Data** â€“ Pulls daily sales data by joining `orders`, `order_details`, and `products`.  
2. **Transform Data** â€“ Calculates total and average revenue per day.  
3. **Load & Visualize** â€“ Saves results into CSV files and generates a line plot of daily revenue.  

---

## ğŸ›  Tools & Technologies
- **Apache Airflow** â€“ Workflow orchestration  
- **PostgreSQL** â€“ Source database  
- **Python (pandas, matplotlib)** â€“ Data transformation & visualization  

---

## â–¶ï¸ How to Run
1. Configure your Airflow environment and add a Postgres connection (`postgres_conn`).  
2. Place the DAG file inside the `dags/` directory.  
3. Start Airflow and trigger the `sales_revenue_pipeline` DAG.  
4. Check the `outputs/` folder (or `/tmp/`) for generated CSVs and revenue plots.  

---

## ğŸ“Š Example Visualization
<img width="600" src="https://github.com/user-attachments/assets/9d67e65f-d6d1-490e-890a-0889901afd4b" />

---

âœ… **Outcome**: Automated daily extraction, computation, and visualization of sales revenue â†’ delivering **clear insights** into revenue trends and supporting **data-driven decisions**.  

